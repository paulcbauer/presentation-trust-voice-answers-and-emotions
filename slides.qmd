---
title: "Affect and Emotions<br>in Political Trust"
subtitle: '<h3>Vortragsreihe "Politik in Europa", 18 June 2024<br>Universität des Saarlandes</h3><br><br>'
author:
  - name: Camille Landesvatter
    affiliations:
      - name: University of Mannheim
  - name: Dr. Paul C. Bauer
    affiliations:
      - name: University of Freiburg, LMU Munich
format:
  revealjs: 
    theme: [white, custom.css]
    embed-resources: true
    slide-number: true
    include-after-body:
      - text: |
          <script type="text/javascript">
          Reveal.addEventListener('slidechanged', (event) => {
            const isSnOn = (event.currentSlide.dataset.hideSlideNumber !== 'true');
            Reveal.configure({ slideNumber: isSnOn });
          });
          </script>
    preview-links: auto
    sc-sb-title: true
    header: Affect and Emotions<br>in Political Trust
filters:
  - reveal-header
---


<!-- 30 Minuten presentation time-->


## Today's Agenda

<font size = "6">
<br>

1. [**Audio Data in the Social Sciences and in Surveys**]{style="color:blue"}
2. [**Emotion Analysis**]{style="color:blue"}
3. [**Working Paper**]{style="color:blue"}: Affect and Emotions in Political Trust




</font size>



## <font size = "14">Audio Data in the Social Sciences and in Surveys</font size> {.center}




## What is Audio Data?

::: header
Audio Data in the Social Sciences and in Surveys
:::

<font size = "6">

- Audio data = information represented in the form of sound waves captured in a digital format (e.g., WAV)

<center>
<figure>

<img src="waveform2.png"/>

<figcaption>Figure 1: Waveform of an audio file (amplitude over time).</figcaption>

</figure>
</center>


::: fragment
- Sources for audio data for the social sciences: Interviews, social media (e.g. live streams, Youtube, TikTok), public speeches and debates, political talk shows and podcasts, press conferences, [recorded survey answers]{style="color:blue"}.
:::


</font size>


------------------------------------------------------------------------

## Characteristics of Audio Data & Answers

::: header
Audio Data in the Social Sciences and in Surveys
:::

<br><br>

<font size = "6">

- Audio Data contains rich information including paralinguistic elements
	- e.g., pitch, volume, laughter and sighs, tone of voice, pause and silence, emotional cues
<br><br>

::: fragment

	
- "System 1" versus "System 2" language/answers [(Lütters et al. 2018)]{style="color:blue"}
	- System 1: intuitive, automatic, and fast thinking → spoken answers
	- System 2: analytical, deliberate, and slow thinking → written answers
:::

</font size>

------------------------------------------------------------------------

## Audio Answers in Surveys

::: header
Audio Data in the Social Sciences and in Surveys
:::

<font size = "6">

- Spoken answers compared to written answers are longer, more elaborate and detailed [(Gavras et al. 2022, Höhne & Gavras 2022, Lütters et al. 2018, Revilla et al. 2020)]{style="color:blue"}
	
::: fragment
Explanations:

- [Gavras et al. 2022]{style="color:blue"}: Audio formats facilitate answer process by enabling **open narration, intuitive and spontaneous answers** (≠ intentional and conscious text answers).

- [Revilla et al. 2020]{style="color:blue"}: Speaking requires **less effort** than typing and voice formats make survey answering **easier/quicker** (lower barriers!).
:::

::: fragment
- But increase response times and non-response rates [(Revilla et al. 2020, Lütters et al. 2018)]{style="color:blue"}
:::

</font size>





------------------------------------------------------------------------

## Methods for the Analysis of Audio Data

::: header
Audio Data in the Social Sciences and in Surveys
:::

<font size = "6">

- Increasing number of methods to analyze audio data (interdisciplinary effort)
	
::: fragment
- Examples of Methods:
	- Natural Language Processing

	- Automatic Speech Recognition ("speech-to-text") (Landesvatter et al. 2023)
		
	- Speaker Diarization / Speaker Identification
	
	- Environmental Sound Analysis
		
	- <u>Speech Emotion Recognition</u>
:::

</font size>



## <font size = "14">Emotion Analysis</font size> {.center}

::: header
Emotion Analysis
:::

## Sentiment Analysis = Emotion Recognition?

::: header
Emotion Analysis
:::

<font size = "6">

- [Affect]{style="color:blue"} = "an umbrella term that is used to refer to both emotions and moods" (Lee, Dirks, and Campagna 2023, 549)


- [Sentiment]{style="color:blue"}: the valence of a feeling (e.g., positive versus negative)

<blockquote>The concept of emotions is not always clearly distinguished from similar phenomena such as mood, affect, and feeling. (Gabriel et al. 2023, 39)</blockquote>

- [Emotions]{style="color:blue"}: more complex and multi-dimensional state of feeling characterized by their intensity driven by different cognitive evaluations (e.g., anger towards politicians) 



</font size>



## Speech Emotion Recognition

::: header
Emotion Analysis
:::

<font size = "6">

- Why use speech (audio data) for Emotion Analysis?
	- → Recognizing emotions from text is difficult because it is stripped of all paralinguistic and acoustic features

::: fragment
- **Speech Emotion Recognition (SER)** is part of the field of Automated Emotion Recognition (intersects with Neurocomputing, Affective Computing) 
:::

::: fragment
- Evolution from traditional Machine Learning models (e.g., logistic regression) to methods based on deep learning/neural networks, e.g. SpeechBrain (Ravanelli et al. 2021)
:::

</font size>





## <font size = "14">**Paper**: Affect and Emotions in Political Trust</font size> {.center}

	
	
	


## Research Question and Motivation (1)

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">



* **Research question**: *Do sentiment & emotions impact political trust judgments?*


<br><br>

::: fragment

1. **Substantive debate**: Rational reasoning vs. affective states
	- Lahno (2020): Game-theory & rational choice
	- "affect-based" form of political trust (e.g., Theiss-Morse and Barton 2017)
<br><br>



:::

</font size>

## Research Question and Motivation (2)

<font size = "6">

<br><br>

2. **Today's relevance of emotions**
	- Changing media environment (e.g., TikTok) &rarr; emotions (fear, anger/rage) used to influence people and their political trust
	- Affective polarization
<br><br>

<!-- , e.g., by providing emotionally arousing content such as immgrants' crime (Gabriel et al. 2023) -->

::: fragment
3. **Methodological**:
	- Extend regression-based analysis through open-ended probing data
	- Explore audio (and text) data to measure emotions & their influence on political trust



:::

</font size>


## Theory and hypotheses
- "**Automatic Hot Cognition**" (Lodge and Taber 2013): all sociopolitical concepts that have been evaluated in the past are affectively charged 
	- &rarr; affective charge is automatically activated within milliseconds on mere exposure to the concept
<br><br>

- Open-ended survey answers on reasons for respondents’ trust include both non-neutral sentiment **(H1a)** as well as emotional, i.e., non-neutral language **(H1b)**
- The sentiment or emotion expressed in open-ended survey answers is correlated with the closed-ended trust score
	- Positive (negative) sentiment has a positive (negative) effect on political trust **(H2a)**
	- Emotion of happiness (anger/sadness) has a positive (negative) effect on political trust **(H2b)**


<!-- the “hot cognition” hypothesis, which posits that all sociopolitical concepts that have been evaluated in the past are affectively charged and that this affective charge is automatically activated within milliseconds on mere exposure to the concept, appreciably faster than conscious appraisal of the object. 

guided by automaticity in which the retrieval
and processing of information is guided by affect. The authors also call such judgements
“snap judgments” (Lodge and Taber 2013, 10). The term “hot cognition” refers to the
idea that concepts (e.g. an idea, a group, a political entity) are instantly and without
intentional control classified as either good or bad (Lodge and Taber 2013, 44), based
on the integration of thoughts and feelings associated with one’s conscious and unconscious
assessments. The valence of concepts is thus retrieved from an associated affect,
allowing the brain “to use affect as real-time information to promote quick, efficient,
spontaneous responses” (Lodge and Taber 2013, 48).

-->

## Questionnaire Design

::: header
Affect and Emotions in Political Trust
:::

<table style="width: 899px;">
<tbody>
<tr style="height: 63.5px;">
<td style="width: 165.875px; height: 63.5px;">Political Trust Question</td>
<td style="width: 515.125px; height: 63.5px;">&ldquo;How often can you trust the federal government in Washington to do what is right?&rdquo; (**ANES**)</td>
<td style="width: 515.125px; height: 63.5px;">5 closed-ended categories [Never (0); Some of the time (1); About half of the time (2); Most of the time (3); Always (4)]</td>
</tr>
<tr style="height: 143px;">
<td style="width: 165.875px; height: 143px;">Probing Question&nbsp;</td>
<td style="width: 515.125px; height: 143px;">"The previous question was: &lsquo;How often can you trust the federal government in&nbsp;Washington to do what is right?&rsquo;.<br>Your answer was: &lsquo;*About half of the time*&rsquo;.<br>In your own words, please explain why you selected this answer.&rdquo;</td>
<td style="width: 515.125px; height: 143px;">open-ended, audio request, SVoice tool (Höhne, Gavras and Qureshi 2021)</td>
</tr>
</tbody>
</table>


------------------------------------------------------------------------

## Data: Overview

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- Self-administered web survey (prolific), September 6 to October 27, 2023

- U.S. non-probability sample; $n$=1,474 with 491 open-ended audio answers (33% response rate)
    
- quota-based (U.S. Census Bureau 2015) with challenges in obtaining sufficient participants in the oldest age category (58+)

</font size>
    
    
------------------------------------------------------------------------





## Methods

::: header
Affect and Emotions in Political Trust
:::

<div style="text-align: center;">

<figure>

<img src="paper3/workflow.excalidraw.png"/>

<figcaption>Figure 1: Methods for Sentiment and Emotion Analysis.</figcaption>


</figure>

------------------------------------------------------------------------


## Data: Example
```{r}
library(knitr)
library(tidyverse)
library(kableExtra)
data <- read_csv("data_presentation.csv")
data <- data %>%
	group_by(speechbrain_classification,
					 sentiment_GPT) %>% 
	arrange(speechbrain_classification,
					 sentiment_GPT) %>%
	mutate(trust_in_government = trust_in_government - 2) %>% # 4 = Always; Never = 0
	# mutate(trust_in_government = ifelse(trust_in_government==5, NA, trust_in_government)) %>%	
	slice(2) %>%
	ungroup() %>%
	slice(1 ,2, 6, 7, 9, 10, 11)

#write_csv(data, "data_presentation_selected.csv")

read_csv("data_presentation_selected.csv") %>%
	mutate(speechbrain_classification = recode(speechbrain_classification,
		   "['ang']" = "Anger",
		   "['neu']" = "Neutral",
		   "['sad']" = "Sadness",
		   "['hap']" = "Happiness")) %>%
	rename("Political trust (0-4)" = trust_in_government,
				 "Probing question" = transcription,
				 "Emotion (Speechbrain)" = speechbrain_classification,
				 "Sentiment (BERT)" = sentiment_BERT,
				 "Sentiment (GPT)" = sentiment_GPT) %>% 
	slice(1:8) %>%
  slice(-2, -4, -7) %>%
  kable(format = "html", table.attr = "style='width:100%;'") %>%
  kable_styling(font_size = 24) %>%
	column_spec(1, width = "8em", background = "yellow")  %>%
  column_spec(2, width = "60em", background = "yellow")

```



## Results: Sentiment distribution (H1a, text data)

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- The commonly used trust in government question used in many surveys produces predominantly negative associations.

::: {style="text-align: center;"}
<figure>

<img src="paper3/sentiment-distribution.png" width="1400" height="350"/>

<figcaption>Figure 2: Sentiment Classification with three categories by classifier (BERT vs. GPT).<br><em>Note.</em> n=491 open-ended answers.</figcaption>

</figure>
:::

</font size>

------------------------------------------------------------------------

## Results: Sentiment & political trust (H2a, text data)

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- Associations with a positive sentiment positively influence trust scores, and vice versa
	- → Associations and their sentiment matter

::: {style="text-align: center;"}
<figure>

<img src="paper3/sentiment-regression.png" width="1400" height="350"/>

<figcaption>Figure 3: Linear model of sentiment and a five-category trust score (bi- and multivariate).<br><em>Note.</em> GPT-based classification. Reference category is negative sentimemt.</figcaption>

</figure>
:::

</font size>

------------------------------------------------------------------------

## Results: Emotions distribution (H1b, audio data)

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- Only 17% of the probing answers contain emotional speech.

::: {style="text-align: center;"}
<figure>

<img src="paper3/emotion-distribution.png" width="1400" height="350"/>

<figcaption>Figure 4: Emotion Classification obtained from SpeechBrain.<br><em>Note.</em> Analysis of n=491 open-ended answers. Number of observations for each sentiment category: 408 (neutral), 44 (angry), 18 (sad), 21 (happy).</figcaption>

</figure>
:::

</font size>

------------------------------------------------------------------------

## Results: Emotions & political trust (H2b, audio data)

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- Respondents with a happy emotional condition have increased trust scores.

::: {style="text-align: center;"}
<figure>

<img src="paper3/emotion-regression.png" width="1400" height="350"/>

<figcaption>Figure 5: Linear model of emotion and a five-category trust score (bi- and multivariate).<br><em>Note.</em> SpeechBrain-based classification.</figcaption>

</figure>
:::

</font size>




------------------------------------------------------------------------

## Conclusion and discussion

::: header
Affect and Emotions in Political Trust
:::

<font size = "6">

- Sentiment related to trust judgments, but no consistent effect of emotions (only happiness)
- NLP & AI & New forms of data introduce new opportunities for measurement

::: fragment
Limitations: Non-probability sample; other probing wording; small response rates (33%); discrete emotions; combine text & audio/sound; 
:::
::: fragment
- Survey setting not "emotional" enough? What is the setting?
:::
::: fragment
- How does SpeechBrain classify? Can we generate a human benchmark?
:::
::: fragment
- Other challenges: Privacy & reproducibility
:::


<!-- speechbrain has not been used in social science research so far and we need more applications with other survey datasets -->

</font size>


------------------------------------------------------------------------

## <font size = "14"> Thank you for your Attention! </font size> {.center}

------------------------------------------------------------------------


------------------------------------------------------------------------

## <font size = "14"> How could future research on voice and emotions look like?  </font size> {.center}

------------------------------------------------------------------------

## Outlook on future research agenda

::: header
Outlook
:::

<font size = "6">

- Audio data plays a crucial role for studying societies, as spoken language is one of humanity's most important means of communication, expression and information exchange in various fields (e.g., public speeches and debates, political talk shows and podcasts, press conferences).

- → We need more applied research to gain more experiences with this type of data.

::: fragment
- Subfields to research: speech-to-text algorithms (Landesvatter, Behnert, Bauer 2023, Meitinger, Sluis, Schonlau 2024), ethical considerations and privacy concerns, survey and experiments design to collect audio data, etc.
:::

::: fragment
- Multi-disciplinary approaches are useful (e.g., experts from linguistics, sociology, psychology, and computer science).
:::

<!-- Examination of ethical considerations and privacy concerns surrounding the collection and use of audio data in research. -->

</font size>


------------------------------------------------------------------------

## Speech-to-Text algorithms

::: header
Outlook
:::

<font size = "6">

- Landesvatter, Camille, Jan Behnert, and Paul C. Bauer. 2023. “Comparing Speech-to-text Algorithms for Transcribing Voice Data from Surveys.” SocArXiv. October 10. doi:10.31235/osf.io/vk6wj.

::: {style="text-align: center;"}
<figure>

<img src="asr-2024.png" width="600" height="310"/>


</figure>
:::


</font size>




## Speechbrain
- **SpeechBrain**: open-source deep learning toolkit built on PyTorch for speech and audio processing tasks
- **Emotion detection**: 2021 pre-trained model based on wav2vec 2.0 architecture (orginally used for speech recognition)
	- Used **Interactive Emotional Dyadic Motion Capture (IEMOCAP)** dataset for training (80% accuracy across different emotions)
- **Interactive Emotional Dyadic Motion Capture (IEMOCAP) dataset**: ~12 hours of annotated recordings, encompassing dialogues from 10 speakers (utterances)
	- six human evaluators assessed emotional categories of the database (three
per utterance) (Busso et al. 2008)
	- one of 3 most widely used SER datasets (Wang et al. 2021).


## Speechbrain accuracy
- Our validation ~ 40 answers (single rater)
	- Seems to work but also difficult to identify emotions
- Is the human ear reliable enough to recognize emotions (pitch, speed, pauses, etc.) & independently from the text?
	- Requires training...

## Sentiment accuracy



<center>
<figure>

<img src="tableA1.png" width="680"/>

</figure>
</center>

<center>
<figure>

<img src="tableA2.png" width="680"/>

</figure>
</center>


## References {data-hide-slide-number="true"}

<font size = "4">

Gabriel, Maier, Masch, and Renner. 2023. Political Leaders, the Display of Emotions, and the Public: An Empirical Study on the Coverage and Effects of Emotions in German Politics. Nomos.

Gavras, Höhne, Blom, and Schoen. 2022. “Innovating the collection of open-ended answers: The linguistic and content characteristics of written and oral answers to political attitude questions.” Journal of the Royal Statistical Society. Series A, 185(3):872-890.

Grimmelikhuijsen, Stephan. 2012. “Linking Transparency, Knowledge and Citizen Trust in Government: An Experiment.” International Review of Administrative Sciences 78(1):50–73.

Höhne and Gavras. 2022. “Typing or Speaking? Comparing Text and Voice Answers to Open Questions on Sensitive Topics in Smartphone Surveys.” Available at SSRN: https://ssrn.com/abstract=4239015 or http://dx.doi.org/10.2139/ssrn.4239015.

Lee, Kurt, and Rachel L. Campagna. 2023. “At the Heart of Trust: Understanding the Integral Relationship Between Emotion and Trust.” Group & Organization Management 48(2):546–80.

Lodge, Milton, and Charles S. Taber. 2013. The Rationalizing Voter. Cambridge University Press.

Lütters, Friedrich-Freksa, and Egger. 2018.“Effects of Speech Assistance in Online Questionnaires.” Presented at the General Online Research Conference, Vol. 18.

Ravanelli, Parcollet, Plantinga, et al. 2021. “SpeechBrain: A General-Purpose Speech Toolkit.” arXiv.

Revilla, Couper, Bosch, and Asensio. 2020. “Testing the Use of Voice Input in a Smartphone Web Survey.” Social Science Computer Review 38(2):207–24.

Theiss-Morse and Dona-Gene Barton. 2017. “Emotion, Cognition, and Political Trust.” Pp. 160–75 in Handbook on Political Trust. Edward Elgar Publishing.






</font size>